{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitminercondaa6c31f2afe9143f993ded22a64766581",
   "display_name": "Python 3.7.6 64-bit ('miner': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QTW Lab 15\n",
    "\n",
    "## David Josephs, Andy Heroy, Carson Drake, Che' Cobb\n",
    "\n",
    "### April 10, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{}\n",
    "## Introduction\n",
    "\n",
    "For the final case study for DS7333, we were given an unlabled dataset and tasked with providing insight and as to possible cost savings for a business partner. The dataset itself was 160,000 records with 51 unlabeled features.   Our only hint as to its domain is that its origins lie in the insurance industry.  The features themselves are labeled x0-x49 with a binary target category ('y') of 0 or 1.  Our job is to apply machine learning modeling techniques to show a cost savings for our business partner for every correct classification of the target variable.  \n",
    "\n",
    "Seeing as we're dealing with a target variable that is binary, our job will be to select classifciation models that can best address the data.  The classification models we will attempt are as follows.  \n",
    "\n",
    "- Random Forrest\n",
    "- Logistic Regression\n",
    "- XGBoost\n",
    "\n",
    "## Background\n",
    "\n",
    "At its simplest, a classification model trains a model on a sample of training data to then predict what the class of unseen test data.  The metrics for classification models are accuracy, precision, recall and F1-Score.  The main goal of this paper is to minimize false positives and false negatives.  As our business partner has kindly given us a \"cost\" function as to what false positivies and negatives cost our company. \n",
    "\n",
    "- False positive = $10\n",
    "- False negative = $500\n",
    "- True  pos/neg  = $ 0\n",
    "\n",
    "When we evaluate our models, we implement a custom function to incorporate our business partners requirements in a cost function in the scoring section of the algorithm.  Sklearn comes with a handy function called make_scorer that allows us to monitor our models performance our partners cost savings in mind.  For a basic overview of other metrics that are standard in classification.  See Table 1 below\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Accuracy | Accuracy is defined as the number of correct predictions divided  by the total number of predictions. | (True Positive + False Negatives)/Total amount of samples |\n",
    "|:---------:|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------:|\n",
    "| Precision | Precision is defined as the ratio of correctly predicted positives  to the total number of predicted positive observations. | True Positive/(True Positives + False Positives) |\n",
    "| Recall | Recall is defined as the ratio of correct positives to all the  observations in the class | True Positives/(True Positives + False Positives) |\n",
    "| F1-Score | F1 score is defined as the harmonic average of Precision and Recall.  This metric is more useful when you have uneven class balances but it  sometimes useful as it includes false postives and false negatives | 2x(Recall x Precision)/(Recall + Position) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}